{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does drift in the PPC datasets align with variability?\n",
    "\n",
    "We'll use the conditional mean+variance of the neural population activity. \n",
    "We want to know whether Δm, the drift in the location-triggered mean, can be explained by the observed trial to trial variability. \n",
    "\n",
    "Projecting a drift vector along observed variability amounts to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta m^\\top \\Sigma^{-1} \\Delta m\n",
    "\\end{equation}\n",
    "\n",
    "In other words, we'd like to measure drift in units of *standard deviations*, and understand if, in these units, drift is more or less aligned with population variability than expected. One \"control\" to compare against then, is to consider a spherical Gaussian. Neural signals should be standardized (z-scored) first to make this comparison make sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Go through each pair of sessions. Get units in common, and form a Δm and Σ matrix for each location. Get the expected drift relative to the population variability, relative to .. this isn't going to be well defined. Meh.\n",
    "\n",
    "We'd like to use a normalized average overlap between the trial-to-trial variability (conditioned on behavior), and the drift in the average neuronal tuning over days. Drift is measured as a change in the behavior-conditioned mean of the bandpass-filtered z-scored log-calcium transients, $\\Delta \\mu$. \n",
    "\n",
    "If this were the variance, we'd want $\\left<\\Delta x \\Delta x^\\top\\right>$. This is the expected dot-product between the deviations of data vectors from the mean. We want something similar: the expected dot product between the drift $\\Delta \\mu$ and the trial-to-trial fluctuations $\\Delta x$. However, we only want to be sensitive to the orientation of $\\Delta x$, not it's absolute direction, so we take the squares magnitude of this dot product.\n",
    "\n",
    "\\begin{equation}\n",
    "\\left< (\\Delta m^\\top \\Delta x)^2 \\right>\n",
    "=\n",
    "\\left< \\Delta m^\\top \\Delta x \\Delta x^\\top \\Delta m \\right>\n",
    "=\n",
    "\\Delta m^\\top \\left<\\Delta x \\Delta x^\\top \\right> \\Delta m\n",
    "=\n",
    "\\Delta m^\\top \\Sigma \\Delta m\n",
    "\\end{equation}\n",
    "\n",
    "Note that we pulled $ \\Delta m$ out of the expectation because, for a given pair of sessions, it is fixed and not a stochastic variable\n",
    "\n",
    "## Normalize to largest eigenvector\n",
    "\n",
    "The idea is to make it so that if $\\Delta \\mu$ is a \"typical\" vector as predicted by the trial-to-trial variability, then our \"alignment\" metric will return 1. One version of this is to find the largest eigenvector of Σ, which tim called the \"rank 1 approximation\" to the population alignment. This sounds good!\n",
    "\n",
    "In detail: normalize $\\Sigma$ so that $\\lambda_{max}=1$, and normalize $\\Delta\\mu$ to unit length. The rank-1 approximation is just $\\left< (\\Delta\\mu^\\top v_{max})^2 \\right>$\n",
    "\n",
    "See: https://stackoverflow.com/questions/12167654/fastest-way-to-compute-k-largest-eigenvalues-and-corresponding-eigenvectors-with\n",
    "\n",
    "\n",
    "\n",
    "In SciPy, you can use the linalg.eigh function, with the eigvals parameter.\n",
    "\n",
    "    eigvals : tuple (lo, hi) Indexes of the smallest and largest (in ascending order) eigenvalues and corresponding eigenvectors to be returned: 0 <= lo < hi <= M-1. If omitted, all eigenvalues and eigenvectors are returned.\n",
    "\n",
    "Which in your case should be set to (N-k,N-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment Statistics\n",
    "\n",
    "To summarize the alignment of a drift vector $\\Delta \\mu$ with the distribution of inter-trial variability, we consider the trial-averaged mean $\\mu$ and covariance $\\Sigma$ of the neural activity (log calcium-fluorescence signals filtered between 0.03 and .3 Hz and z-scored), conditioned on trial location and the current/previous cue direction. We use the expected squared magnitude of the dot product between the change in trial-conditioned means between days ($\\Delta \\mu$), with the directions of inter-trial variability ($\\Delta z{=}z{-}\\left<z\\right>$) on the first day, which is summarized by the product $\\Delta\\mu^\\top\\Sigma\\Delta\\mu$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "{\\left<|\\Delta\\mu^\\top\\Delta z|^2 \\right>}\n",
    "&={\\left<\\Delta\\mu^\\top\\Delta z \\Delta z^\\top \\Delta\\mu \\right>}\n",
    "\\\\&={\\Delta\\mu^\\top\\left<\\Delta z \\Delta z^\\top\\right>\\Delta\\mu}\n",
    "\\\\&={\\Delta\\mu^\\top\\Sigma\\Delta\\mu}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "To compare pairs of sessions with different amounts of drift and inter-trial variability, we normalize the drift vector to unit length, and normalize the trial-conditioned covariance by its largest eigenvalue $\\lambda_{\\text{max}}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\phi_{\\text{trial}}^2 \n",
    "&= \n",
    "\\frac\n",
    "{\\Delta\\mu^\\top\\Sigma\\Delta\\mu}\n",
    "{|\\Delta\\mu|^2 \\cdot \\lambda_{\\text{max}}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "The statistic $\\phi_{\\text{trial}}$ amounts to a normalized root-mean-squared dot product between the drift direction and the directions of trial-to-trial variability, and equals 1 if the drift aligns perfectly with the direction of largest inter-trial variability. Since randomly oriented drift directions will still align with some directions of variability, the expected squared dot-product between two randomly-oriented $D$-dimensional unit vectors scales as $1/D$. Accounting for the contribution from each dimension of $\\Sigma$, the expected chance alignment is therefore $\\phi^2_0={\\operatorname{tr}(\\Sigma)} / (D \\cdot {\\lambda_{\\text{max}}})$. We use a normalized alignment coefficient $\\rho_{\\text{trial}}$ which is 0 for randomly oriented vectors, and 1 if the drift aligns perfectly with the direction of largest variability:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\rho_{\\text{trial}} &=\n",
    "\\frac\n",
    "{\\phi_{\\text{trial}} - \\phi_0}\n",
    "{1-\\phi_0}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "We define a similar alignment statistic $\\rho_{\\text{coding}}$ to assess how drift aligns with directions of neural variability important for encoding location. We consider the root-mean-squared dot product between the drift $\\Delta\\mu$, and the directions of neural activity ($z$) that vary with location ($x$) on a given trial, i.e. $\\nabla_x z(x)$:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "{\\left<|\\Delta\\mu^\\top\\nabla_x z(x)|^2 \\right>}\n",
    "&= \n",
    "{\\left<\\Delta\\mu^\\top[\\nabla_x z(x)][\\nabla_x z(x)]^\\top \\Delta\\mu \\right>}\n",
    "\\\\&= \n",
    "{\\Delta\\mu^\\top\\left<[\\nabla_x z(x)][\\nabla_x z(x)]^\\top\\right>\\Delta\\mu}\n",
    "\\\\&= \n",
    "{\\Delta\\mu^\\top\\left[\n",
    "\\Sigma_{\\nabla}\n",
    "+\n",
    "\\mu_{\\nabla}\n",
    "\\mu_{\\nabla}^\\top\n",
    "\\right]\\Delta\\mu}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "In contrast to the trial-to-trial variability statistic, this statistic depends on the second moment  $\\Sigma_{\\nabla}+\\mu_{\\nabla}\\mu_{\\nabla}^\\top$, where $\\nabla_x z(x) \\sim \\mathcal N(\\mu_{\\nabla},\\Sigma_{\\nabla})$. We define a normalized $\\phi_{\\text{coding}}^2$ and $\\rho_{\\text{coding}}$ in the same way as $\\phi_{\\text{trial}}^2$ and $\\rho_{\\text{trial}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap with 'orthogonal' space\n",
    "\n",
    " To assess alignment with null directions of a covariance or second moment $\\Sigma$, we define a complementary measure which is a generalization of the dot-product of an angle with it's orthogonal direction in 2D space. Define $\\Sigma^\\bot$, such that $\\Sigma^\\bot + \\Sigma = I \\lambda_{\\text{max}}$ (this is something like an orthogonal complement of a covariance). $\\Sigma^\\bot$ can be computed from $\\Sigma$ by setting eigenvalues $\\lambda_i^\\bot \\gets \\lambda_{\\text{max}}-\\lambda_i$. Or more directly:\n",
    "\\begin{equation}\n",
    "\\Sigma^\\bot = I \\lambda_{\\text{max}} - \\Sigma\n",
    "\\end{equation}\n",
    "\n",
    "Sanity check: confirm that eigenvalues sum to 1. Also confirm that this reduces to usual sine/cosine intution in 2D and if variability is confined to one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine alignment with coding direction\n",
    "\n",
    "To do this, get the distribution of the change in neural states per change in trial location, $\\Delta z$. Because of linearity, $\\left<\\Delta z\\right> = \\mu_2-\\mu_1$. For covariance though we need the cross-correlation, which we did't store. So we recompute this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get population covariability\n",
    "\n",
    "For every session, get available units, get calcium signals, normalize them, get location-triggered statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data location is /home/mer49/Workspace2/PPC_data/\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Add local scripts to path\n",
    "import os,sys\n",
    "sys.path.insert(0,os.path.abspath(\"./\"))\n",
    "import neurotools\n",
    "\n",
    "# Set up cache\n",
    "from neurotools.jobs.initialize_system_cache import initialize_caches,cache_test\n",
    "PYCACHEDIR = os.path.abspath('./')\n",
    "CACHENAME  = 'PPC_cache'\n",
    "from neurotools.tools import ensure_dir\n",
    "ensure_dir(PYCACHEDIR+os.sep+CACHENAME)\n",
    "initialize_caches(\n",
    "    level1  = PYCACHEDIR,\n",
    "    force   = False,\n",
    "    verbose = False,\n",
    "    CACHE_IDENTIFIER = CACHENAME)\n",
    "\n",
    "# Import libraries\n",
    "from neurotools.nlab import *\n",
    "\n",
    "import ppc_data_loader\n",
    "# Set this to the location of the PPC data on your machine\n",
    "ppc_data_loader.path = '/home/mer49/Dropbox (Cambridge University)/Datasets/PPC_data/'\n",
    "\n",
    "from ppc_data_loader   import *\n",
    "from ppc_trial         import *\n",
    "from drift_alignment_routines import *\n",
    "\n",
    "np.seterr(all='raise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute stats for all subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize caches and precompute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "@memoize\n",
    "def get_alignment_statistics(animal,LOWF=None,HIGHF=None):\n",
    "    leftright = [ppc_trial.Trial.CUE_LEFT,ppc_trial.Trial.CUE_RIGHT]\n",
    "    # Get all the activity from all sessions for this animal, for each of the 4 conditions\n",
    "    activity_summary = {}\n",
    "    for CUE,PREV in product(leftright,leftright):\n",
    "        print('Getting trial-conditioned neural sigals for %s %s %s'%(animal,CUE,PREV))\n",
    "        # allμ,allΣ,alldμ,alldΣ,allunits\n",
    "        activity_summary[animal,CUE,PREV] = get_trial_conditioned_population_activity(animal,CUE,PREV,LOWF,HIGHF)\n",
    "        # Not enough memory to leave cached datasets in RAM or open files\n",
    "        release_files(clear_cache=True)\n",
    "    # Lists for storing various alignment coefficients ρ\n",
    "    variables  = 'ρnoise ρcode ρnoise_self ρcode_self ρnoise_chance ρcode_chance'.split()\n",
    "    variables += 'rnoise rcode rnoise_self rcode_self rnoise_chance rcode_chance'.split()\n",
    "    results = {v:[] for v in variables}\n",
    "        \n",
    "    # Find consecutive sessions\n",
    "    sessions = array(get_session_ids(animal))\n",
    "    days     = array(get_days(animal))\n",
    "    ok       = np.where(diff(days)==1)[0]\n",
    "    pairs    = list(zip(ok,sessions[ok],sessions[ok+1]))\n",
    "    \n",
    "    # Compare all pairs of consecutive sessions\n",
    "    for i,s1,s2 in pairs:\n",
    "        # Get units in common\n",
    "        u1,u2 = [good_units_index(animal,s) for s in [s1,s2]]\n",
    "        units = array(sorted(list(set(u1)&set(u2))))\n",
    "        ix1 = [i for i in range(len(u1)) if u1[i] in units]\n",
    "        ix2 = [i for i in range(len(u2)) if u2[i] in units]\n",
    "        # Calculate alignment angle ρ for every location and previous/current cue condition\n",
    "        for CUE,PREV in product(leftright,leftright):\n",
    "            # Get population statistics for both days for this cue condition\n",
    "            allμ,allΣ,alldμ,alldΣ,allunits = activity_summary[animal,CUE,PREV]\n",
    "            μ1,μ2   = allμ[i:i+2]\n",
    "            Σ1,Σ2   = allΣ[i:i+2]\n",
    "            dμ1,dμ2 = alldμ[i:i+2]\n",
    "            dΣ1,dΣ2 = alldΣ[i:i+2]\n",
    "            # Extract the mean drift vector\n",
    "            μ1r,μ2r = μ1[:,ix1],μ2[:,ix2]\n",
    "            Σ1r,Σ2r = Σ1[:,ix1,:][:,:,ix1],Σ2[:,ix2,:][:,:,ix2]\n",
    "            Δμ = μ2r - μ1r\n",
    "            # Extract the coding-relevant distributions\n",
    "            dμ1r,dμ2r = dμ1[:,ix1],dμ2[:,ix2]\n",
    "            dΣ1r,dΣ2r = dΣ1[:,ix1,:][:,:,ix1],dΣ2[:,ix2,:][:,:,ix2]\n",
    "            # Compare the drift direction with the coding axis\n",
    "            # We need the 2nd moment not the covariance \n",
    "            # Since the absolut edisplacement matters\n",
    "            dM21 = dΣ1r + array([outer(μ,μ) for μ in dμ1r])\n",
    "            # Get alignment angle for every location: noise space and code space\n",
    "            results['ρnoise']        += list(arraymap(alignment_angle_normalized       ,Δμ,Σ1r ).ravel())\n",
    "            results['ρcode']         += list(arraymap(alignment_angle_normalized       ,Δμ,dM21).ravel())\n",
    "            results['ρnoise_chance'] += list(arraymap(sample_alignment_angle_normalized,Σ1r ).ravel())\n",
    "            results['ρcode_chance']  += list(arraymap(sample_alignment_angle_normalized,dM21).ravel())\n",
    "            results['ρnoise_self']   += list(arraymap(sample_alignment_self_normalized ,Σ1r ).ravel())\n",
    "            results['ρcode_self']    += list(arraymap(sample_alignment_self_normalized ,dM21).ravel())\n",
    "            # unnormalized variants\n",
    "            results['rnoise']        += list(arraymap(alignment_angle_unnormalized       ,Δμ,Σ1r ).ravel())\n",
    "            results['rcode']         += list(arraymap(alignment_angle_unnormalized       ,Δμ,dM21).ravel())\n",
    "            results['rnoise_chance'] += list(arraymap(sample_alignment_angle_unnormalized,Σ1r ).ravel())\n",
    "            results['rcode_chance']  += list(arraymap(sample_alignment_angle_unnormalized,dM21).ravel())\n",
    "            results['rnoise_self']   += list(arraymap(sample_alignment_self_unnormalized ,Σ1r ).ravel())\n",
    "            results['rcode_self']    += list(arraymap(sample_alignment_self_unnormalized ,dM21).ravel())\n",
    "    release_files(clear_cache=True)\n",
    "    return {v:array(results[v]).ravel() for v in variables}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWF  = .03\n",
    "HIGHF = .30\n",
    "get_alignment_statistics(1,LOWF,HIGHF);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting trial-conditioned neural sigals for 2 0 0\n",
      "Getting trial-conditioned neural sigals for 2 0 1                     \n",
      "Getting trial-conditioned neural sigals for 2 1 0                     \n",
      "Getting trial-conditioned neural sigals for 2 1 1                     \n",
      "Getting trial-conditioned neural sigals for 3 0 0                     \n",
      "[###############################################   ] 94% 316/333      "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    activity_summary\n",
    "except:\n",
    "    activity_summary = {}\n",
    "animals = get_subject_ids()\n",
    "for a in animals:\n",
    "    results = get_alignment_statistics(a,LOWF,HIGHF)\n",
    "    for k,v in results.items():\n",
    "        activity_summary[a,k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBINS = 40\n",
    "XMIN  = -0.1\n",
    "XMAX  = 1\n",
    "bins  = linspace(XMIN,XMAX,NBINS)\n",
    "f     = lambda y:y\n",
    "alpha = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots: notches reflect bootstrap 95% confidence interval of the median, 1000 samples. Boxes reflect inter-quartile range. Whiskers reflect inner 95th percentile of the data distribution. Dashed vertical line reflects the upper 95th percentile of the chance distribution (black box plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,4))\n",
    "\n",
    "for ia,animal in enumerate([1,3,4,5]):    \n",
    "    vars  = [activity_summary[animal,'rcode_chance']]\n",
    "    vars += [activity_summary[animal,'rcode']]\n",
    "    vars += [activity_summary[animal,'rcode_self']]\n",
    "    \n",
    "    vars += [activity_summary[animal,'rnoise_chance']]\n",
    "    vars += [activity_summary[animal,'rnoise']]\n",
    "    vars += [activity_summary[animal,'rnoise_self']]\n",
    "    N = len(vars)\n",
    "\n",
    "    text(2+ia*(N+1),-0.05,'Mouse %d'%animal,ha='center',va='top')\n",
    "    \n",
    "    bp = {}\n",
    "    for i,(distr,color) in enumerate(zip(vars,\n",
    "                                 [BLACK,AZURE,OCHRE,MAUVE,TURQUOISE,RUST])):\n",
    "        bp[i] = boxplot(distr,\n",
    "                     positions=[i+1+ia*(N+1)],\n",
    "                     widths=0.5,\n",
    "                     vert=True,\n",
    "                     showfliers=False,\n",
    "                     patch_artist=True,\n",
    "                     whis=[2.5, 97.5],\n",
    "                     notch=True,\n",
    "                     bootstrap=1000,\n",
    "                     medianprops={'linewidth':2,'color':WHITE})\n",
    "        \n",
    "        nicebp(bp[i],color=color,linewidth=1)\n",
    "        if i==0 or i==3:\n",
    "            py = percentile(distr,95)\n",
    "            px = ia*(N+1)+i+0.5\n",
    "            plot([px,px+3],[py,py],lw=1,color=color,linestyle=':',zorder=1000)\n",
    "\n",
    "labels = [bp[i][\"boxes\"][0] for i in range(6)]\n",
    "baselegend(labels, ['Chance level (coding)',\n",
    "                'Coding directions',\n",
    "                'Coding subspace self alignment',\n",
    "                'Chance level (noise)',\n",
    "                'Noise directions',\n",
    "                'Noise subspace self alignment'], \n",
    "          ncol=2)\n",
    "\n",
    "simpleraxis()\n",
    "yticks([0,1])\n",
    "xticks([])\n",
    "xlim(0,4*(1+N))\n",
    "fudgey()\n",
    "ylabel(r'$\\rho$')\n",
    "title('Alignment of $\\Delta\\mu$ with coding, noise subspaces')\n",
    "\n",
    "tight_layout()\n",
    "savefigure('Alignment_unnormalized_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,4))\n",
    "\n",
    "for ia,animal in enumerate([1,3,4,5]):\n",
    "    \n",
    "    vars = [activity_summary[animal,'ρ%s'%var] for var in ('code','noise')]\n",
    "    vars = [cat([activity_summary[animal,'ρcode_chance'],activity_summary[animal,'ρnoise_chance']])] + vars\n",
    "    N = len(vars)\n",
    "    text(2+ia*(N+1),-0.15,'Mouse %d'%animal,ha='center',va='top')\n",
    "    bp = {}\n",
    "    for i,(distr,color) in enumerate(zip(vars,[BLACK,AZURE,OCHRE])):\n",
    "        bp[i] = boxplot(distr,\n",
    "                     positions=[i+1+ia*(N+1)],\n",
    "                     widths=0.5,\n",
    "                     vert=True,\n",
    "                     showfliers=False,\n",
    "                     patch_artist=True,\n",
    "                     whis=[2.5, 97.5],\n",
    "                     notch=True,\n",
    "                     bootstrap=1000,\n",
    "                     medianprops={'linewidth':2,'color':WHITE})\n",
    "        \n",
    "        nicebp(bp[i],color=color,linewidth=1.5)\n",
    "    i = 0 \n",
    "    pooled_chance = concatenate([activity_summary[animal,'ρcode_chance'],activity_summary[animal,'ρnoise_chance']])\n",
    "    py = percentile(pooled_chance,95)\n",
    "    px = ia*(N+1)+i+0.5\n",
    "    plot([px,px+3],[py,py],lw=1,color=BLACK,linestyle=':',zorder=1000)\n",
    "        \n",
    "labels = [bp[i][\"boxes\"][0] for i in range(len(bp))]\n",
    "legend(labels, ['Chance','Coding directions','Noise directions'], \n",
    "       loc='center left', \n",
    "       bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "simpleraxis()\n",
    "ylim(ylim()[0],1)\n",
    "yticks([0,1])\n",
    "xticks([])\n",
    "axhline(0,lw=1,color='k')\n",
    "axhline(1,lw=1,color='k')\n",
    "xlim(0,4*(1+N))\n",
    "fudgey()\n",
    "ylabel('      $\\\\rho$')\n",
    "title('Alignment of $\\Delta\\mu$ with coding, noise subspaces')\n",
    "\n",
    "tight_layout()\n",
    "savefigure('Alignment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
